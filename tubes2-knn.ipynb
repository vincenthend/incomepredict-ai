{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas Besar IF3170\n",
    "## Aplikasi Web Prediksi Income Per Tahun\n",
    "\n",
    "### Nama Kelompok : 49\n",
    "### Anggota :\n",
    "    1. Finiko Kasula Novenda - 13515029\n",
    "    2. M. Dicky Andika Putra - 13515044\n",
    "    3. Vincent Hendryanto Halim - 13515089\n",
    "    4. Mikhael Artur Darmakesuma - 13515099\n",
    "    5. William - 13515144\n",
    "### Hasil Analisis Data\n",
    "#### Jenis data\n",
    "Data yang tersedia dapat diklasifikasikan menjadi 2 jenis, yaitu data kontinu dan data kategorial.\n",
    "- Kolom yang mengandung data kontinu antara lain: age, fnlwgt,education-num, capital-gain, capital-loss, hours-per-week\n",
    "- Kolom yang mengandung data kategorial antara lain: workclass,education,marital-status,occupation, relationship, race, sex, native-country\n",
    "\n",
    "#### Penanganan data tidak lengkap\n",
    "Dari data awal, masih ada data yang mengandung informasi yang tidak lengkap, ditandai dengan karakter '?'\n",
    "Data yang hilang ini kami ubah menjadi modus keseluruhan data. Data yang hilang hanya terdapat pada kolom data kategorial, dan data kategorial tidak dapat dihitung mean, sehingga dipilih modus.\n",
    "#### Perubahan menjadi data numerik\n",
    "Classifier yang tersedia pada scikit, baik KNN, ID3, MLP maupun NaiveBayes hanya dapat menangani data bersifat numerik.\n",
    "Untuk itu data-data yang bersifat kategorial perlu diubah. Data kategorial ini diubah menggunakan fitur get_dummies pada panda. Dengan get_dummies ini, akan terbentuk kolom baru sebesar sparsity suatu kolom kategorial. Misalkan kolom \"Sex\" memiliki nilai Male atau Female. Setelah diubah, kolom Sex akan berubah menjadi 2 kolom baru yaitu kolom Sex_Male, dan kolom Sex_Female. Jika sebelumnya kolom Sex bernilai \"Male\", setelah perubahan kolom Sex_Male akan bernilai 1 dan kolom Sex_Female bernilai 0.\n",
    "#### Penanganan data tambahan\n",
    "Kolom fnlwgt, race, dan native-country didrop karena kolom tersebut dinilai tidak representatif untuk kelas hasil sesuai dengan analisis menggunakan histogram pada \n",
    "#### Ukuran Kinerja\n",
    "Kinerja pada tugas kali ini diukur dengan menggunakan fungsi bawaan sklearn yaitu tree_model.score yang menghitung akurasi dari model terhadap data tes yang diberikan. Akurasi dihitung berdasarkan data yang berhasil diprediksi dengan benar dibanding total semua data. <i>Accuracy</i> = (Tp + Tn)/(Tp + Fp + Tn + Fn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Library Import\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import graphviz\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "\n",
    "# Algorithm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributeNames = [\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"target\"]\n",
    "income = pd.read_csv('data/CensusIncome.data.csv', header=None, names = atributeNames, sep = \",\\s\", engine=\"python\", na_values=\"?\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mengubah NaN menjadi Most Frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = income.apply(lambda x:x.fillna(x.value_counts().index[0])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = income.drop(columns=['fnlwgt', 'race', 'native-country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panda get_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomeFinal = pd.get_dummies(income, columns=[\"workclass\", \"education\",\"marital-status\",\"occupation\",\"relationship\",\"sex\"])\n",
    "x = incomeFinal[[i for i in list(incomeFinal.columns) if i != 'target']].values\n",
    "y = incomeFinal['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pemilihan Algoritma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 85.351\n"
     ]
    }
   ],
   "source": [
    "nbrs = KNeighborsClassifier(n_neighbors=28)\n",
    "score = cross_val_score(nbrs, x, y, cv=10)\n",
    "print(\"Score : %.3f\" % (score.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23232  1488]\n",
      " [ 3282  4559]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(nbrs,x,y,cv=10)\n",
    "print(confusion_matrix(y,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 83.873\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver='adam', alpha=1e-3, hidden_layer_sizes=(10,70), random_state=1)\n",
    "score = cross_val_score(mlp, x, y, cv=10).mean()\n",
    "print(\"Score : %.3f\" % (score.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22796  1924]\n",
      " [ 3327  4514]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(mlp, x, y, cv=10)\n",
    "print(confusion_matrix(y,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 81.367\n"
     ]
    }
   ],
   "source": [
    "foldNaiveBayes = GaussianNB()\n",
    "score = cross_val_score(foldNaiveBayes, x, y, cv = 10)\n",
    "print(\"Score : %.3f\" % (score.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20392  4328]\n",
      " [ 1739  6102]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(foldNaiveBayes, x, y, cv = 10)\n",
    "print(confusion_matrix(y,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Decision Tree ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 82.203\n"
     ]
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier(criterion='entropy', max_features=28) #nilai 28 diambil dari percobaan\n",
    "score = cross_val_score(dt, x, y, cv = 10)\n",
    "print(\"Score : %.3f\" % (score.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21993  2727]\n",
      " [ 3119  4722]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(dt, x, y, cv = 10)\n",
    "print(confusion_matrix(y,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Full Training\n",
    "\n",
    "Dipilih algoritma Decision Tree ID3 Karena menghasilkan nilai akurasi yang paling baik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_out = tree.DecisionTreeClassifier(criterion='entropy', max_features=28) # Mungkin pakai max_features?\n",
    "model_out = KNeighborsClassifier(n_neighbors=28)\n",
    "model_out = model_out.fit(x,y)\n",
    "\n",
    "pickle.dump(model_out,open(\"out.pkl\", \"wb+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('data/CensusIncome.test.csv', header=None, names = atributeNames, sep = \",\\s\", engine=\"python\", na_values=\"?\", comment=\"|\");\n",
    "test_data = test_data.apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
    "test_data = test_data.drop(columns=['fnlwgt','race', 'native-country'])\n",
    "test_data = pd.get_dummies(test_data, columns=[\"workclass\",\"education\",\"marital-status\",\"occupation\",\"relationship\",\"sex\"])\n",
    "\n",
    "test_dataframe = pd.DataFrame(columns = incomeFinal.columns)\n",
    "test_dataframe.append(test_data)\n",
    "\n",
    "test_dataframe = pd.concat([test_dataframe, test_data], axis=0)\n",
    "test_dataframe = test_dataframe.fillna(0)\n",
    "\n",
    "x_test = test_dataframe[[i for i in list(test_dataframe.columns) if i != 'target']].values\n",
    "y_test = pd.DataFrame(test_dataframe['target'].values)\n",
    "\n",
    "model = pickle.load(open(\"out.pkl\",\"rb+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 85.59\n"
     ]
    }
   ],
   "source": [
    "score = model.score(x_test, y_test)\n",
    "print(\"Score : %.2f\" % (score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11685   751]\n",
      " [ 1596  2250]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
