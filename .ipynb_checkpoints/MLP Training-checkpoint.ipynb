{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Census Income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Library Import and Initializations\n",
    "# Data Library and Preprocessing\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# Algorithm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Test Type Algorithm\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV\n",
    "data = pd.read_csv('data/CensusIncome.data.csv', header=None, sep = \",\\s\", engine=\"python\", na_values=[\"?\"])\n",
    "\n",
    "# Turn string into integer, and return converted NaN to NaN\n",
    "label = defaultdict(LabelEncoder)\n",
    "data = data.fillna(\"NaN\")\n",
    "data = data.apply(lambda x: x if x.dtype != 'O' else label[x.name].fit_transform(x))\n",
    "\n",
    "for x in label:\n",
    "    if(\"NaN\" in label[x].classes_):\n",
    "        data[x] = data[x].replace(label[x].transform([\"NaN\"])[0], np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Imputed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill NaN values with dummy data, and then transform it using transform\n",
    "imp = Imputer(strategy='mean', axis=0)\n",
    "\n",
    "data_impute = data.copy(deep = True);\n",
    "data_impute = data_impute.fillna(\"NaN\")\n",
    "\n",
    "imp.fit(data_impute)\n",
    "data_impute = DataFrame(imp.transform(data_impute))\n",
    "\n",
    "# Encode categorical data\n",
    "data_impute = pd.get_dummies(data=data_impute, columns=list(label.keys()))\n",
    "data_impute_x, data_impute_y = data_impute.iloc[:,:-1], data_impute.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating no NaN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop datas with NaN(null) values\n",
    "data_drop = data.copy()\n",
    "data_drop = data_drop.dropna(axis=0, how='any')\n",
    "\n",
    "# Encode categorical data\n",
    "data_drop = pd.get_dummies(data=data_drop, columns=list(label.keys()))\n",
    "data_drop_x, data_drop_y = data_drop.iloc[:,:-1], data_drop.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.75107723  0.75107723  0.75107723  0.75107723  0.75099469  0.75099469\n",
      "  0.75099469  0.75099469  0.75124378  0.75124378]\n",
      "[ 0.75928769  0.75982801  0.75952088  0.75921376  0.75952088  0.80251843\n",
      "  0.75982801  0.75982801  0.75982801  0.75952088]\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5,2), random_state=1)\n",
    "\n",
    "# Drop Data\n",
    "print (cross_val_score(mlp, data_drop_x, data_drop_y, cv=10))\n",
    "\n",
    "# Impute Data\n",
    "print (cross_val_score(mlp, data_impute_x, data_impute_y, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "print (cross_val_score(dt, data_drop_x, data_drop_y, cv=10))\n",
    "print (cross_val_score(dt, data_impute_x, data_impute_y, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
