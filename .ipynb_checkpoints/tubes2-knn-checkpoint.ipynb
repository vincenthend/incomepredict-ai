{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas Besar IF3170\n",
    "## Aplikasi Web Prediksi Income Per Tahun\n",
    "\n",
    "### Nama Kelompok : 49\n",
    "### Anggota :\n",
    "    1. Finiko Kasula Novenda - 13515029\n",
    "    2. M. Dicky Andika Putra - 13515044\n",
    "    3. Vincent Hendryanto Halim - 13515089\n",
    "    4. Mikhael Artur Darmakesuma - 13515099\n",
    "    5. William - 13515144\n",
    "### Hasil Analisis Data\n",
    "#### Jenis data\n",
    "Data yang tersedia dapat diklasifikasikan menjadi 2 jenis, yaitu data kontinu dan data kategorial.\n",
    "- Kolom yang mengandung data kontinu antara lain: age, fnlwgt,education-num, capital-gain, capital-loss, hours-per-week\n",
    "- Kolom yang mengandung data kategorial antara lain: workclass,education,marital-status,occupation, relationship, race, sex, native-country\n",
    "\n",
    "#### Penanganan data tidak lengkap\n",
    "Dari data awal, masih ada data yang mengandung informasi yang tidak lengkap, ditandai dengan karakter '?'\n",
    "Data yang hilang ini kami ubah menjadi modus keseluruhan data. Data yang hilang hanya terdapat pada kolom data kategorial, dan data kategorial tidak dapat dihitung mean, sehingga dipilih modus.\n",
    "#### Perubahan menjadi data numerik\n",
    "Classifier yang tersedia pada scikit, baik KNN,ID3,MLP,NaiveBayes hanya dapat menangani data bersifat numerik.\n",
    "Untuk itu data-data yang bersifat kategorial perlu diubah. Data kategorial ini diubah menggunakan fitu get_dummies pada panda. Dengan get_dummies ini, akan terbentuk kolom baru sebesar sparsity suatu kolom kategorial. Misalkan kolom \"Sex\" memiliki nilai Male atau Female. Setelah diubah, kolom Sex akan berubah menjadi 2 kolom baru yaitu Sex_Male, dan Sex_Female. Jika sebelumnya kolom Sex bernilai \"Male\", setelah perubahan kolom Sex_Male akan bernilai 1 dan Sex_Female bernilai 0.\n",
    "#### Ukuran Kinerja\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Library Import\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import graphviz\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "\n",
    "# Algorithm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributeNames = [\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"target\"]\n",
    "income = pd.read_csv('data/CensusIncome.data.csv', header=None, names = atributeNames, sep = \",\\s\", engine=\"python\", na_values=\"?\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mengubah NaN menjadi Most Frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = income.apply(lambda x:x.fillna(x.value_counts().index[0])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = income.drop(columns=['race', 'native-country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panda get_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomeFinal = pd.get_dummies(income, columns=[\"workclass\", \"education\",\"marital-status\",\"occupation\",\"relationship\",\"sex\"])\n",
    "x = incomeFinal[[i for i in list(incomeFinal.columns) if i != 'target']].values\n",
    "y = incomeFinal['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pemilihan Algoritma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs = KNeighborsClassifier(n_neighbors=7)\n",
    "score = cross_val_score(nbrs, x, y, cv=10)\n",
    "print(\"Score: \", score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(nbrs,x,y,cv=10)\n",
    "print(confusion_matrix(y,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(solver='adam', alpha=1e-3, hidden_layer_sizes=(10,70), random_state=1)\n",
    "\n",
    "print (\"Score : \", cross_val_score(mlp, x, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(mlp, x, y, cv=10)\n",
    "print(confusion_matrix(y,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldNaiveBayes = GaussianNB()\n",
    "score = cross_val_score(foldNaiveBayes, x, y, cv = 10)\n",
    "print(\"Score: \", score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(foldNaiveBayes, x, y, cv = 10)\n",
    "print(confusion_matrix(y,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Decision Tree ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 81.64\n"
     ]
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "score = cross_val_score(dt, x, y, cv = 10)\n",
    "print(\"Score : %.2f\" % (score.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21629  3091]\n",
      " [ 2907  4934]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(dt, x, y, cv = 10)\n",
    "print(confusion_matrix(y,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Full Training\n",
    "\n",
    "Dipilih algoritma Decision Tree ID3 Karena menghasilkan nilai akurasi yang paling baik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_out = tree.DecisionTreeClassifier(criterion='entropy') # Mungkin pakai max_features?\n",
    "dt_out = dt_out.fit(x,y)\n",
    "\n",
    "pickle.dump(dt_out,open(\"out.pkl\", \"wb+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('data/CensusIncome.test.csv', header=None, names = atributeNames, sep = \",\\s\", engine=\"python\", na_values=\"?\", comment=\"|\");\n",
    "test_data = test_data.apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
    "test_data = test_data.drop(columns=['race', 'native-country'])\n",
    "test_data = pd.get_dummies(test_data, columns=[\"workclass\",\"education\",\"marital-status\",\"occupation\",\"relationship\",\"sex\"])\n",
    "\n",
    "test_dataframe = pd.DataFrame(columns = incomeFinal.columns)\n",
    "test_dataframe.append(test_data)\n",
    "\n",
    "test_dataframe = pd.concat([test_dataframe, test_data], axis=0)\n",
    "test_dataframe = test_dataframe.fillna(0)\n",
    "\n",
    "x_test = test_dataframe[[i for i in list(test_dataframe.columns) if i != 'target']].values\n",
    "y_test = pd.DataFrame(test_dataframe['target'].values)\n",
    "\n",
    "tree_model = pickle.load(open(\"out.pkl\",\"rb+\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 75.87\n"
     ]
    }
   ],
   "source": [
    "score = tree_model.score(x_test, y_test)\n",
    "print(\"Score : %.2f\" % (score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10901  1535]\n",
      " [ 1440  2406]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = tree_model.predict(x_test)\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
